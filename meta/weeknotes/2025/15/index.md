# 2025 - Week 15

## Ever tried. Ever failed. No matter. Try again. Fail again. Fail better. And, just occasionally, succeed

If you tuned in [last time out](https://ukparliament.github.io/ontologies/meta/weeknotes/2025/12/), you'll know that attempts to upgrade our aging - some may suggest decrepit - [triplestore](https://en.wikipedia.org/wiki/Triplestore) [did not go quite to plan](https://ukparliament.github.io/ontologies/meta/weeknotes/2025/12/#it-is-now-saturday). Despite our Jianhan fine-tuning every pipe in and every pipe out, the bit between the triplestore and our [Solr](https://en.wikipedia.org/wiki/Apache_Solr) instance exhibited what might be called 'unexpected behaviours'.

Which is a damn shame, because the old thing is on its last legs, taking upwards of two minutes to save a single record. Given a 'typical' sitting day sees this button pressed over 1,000 times, that's a lot of thumb twiddling for our crack team of librarians to endure. Putting both patience and sanity at stake. A quick back of a fag packet calculation reveals that's 33 hours a day spent waiting for things to save. Or a working librarian week, give or take tea breaks.

Coping strategies have been adopted, Librarian Steve admitting to opening a dozen browser tabs and pressing save on them all before he's even had his morning coffee. But imagine pressing the 'add to cart' button on your favourite e-commerce solution and being expected to wait two minutes for that shopping adrenaline hit. It hardly '[meets the expectations of the internet age](https://www.linkedin.com/pulse/definitionofdigitalcom-tom-loosemore)', as the saying goes.

Whilst the less sanguine may have judged the outcome of Jianhan's endeavours on the basis of a successful upgrade, we pride ourselves on taking a more philosophical approach. Learning is also success, we tell ourselves. And learn Jianhan did. Head buried deep in code, he finally announced he was happy with his changes. Librarians tested and also declared themselves happy.

So when Thursday came around, Jianhan once again pressed whatever buttons it is he presses, [Librarian Anya](https://bsky.app/profile/anyaso.bsky.social) marshalled her troops, [Delivery Manager Lydia](https://bsky.app/profile/lydiakeegal.bsky.social) stepped into the breach and the damned thing worked. Wow. Wonders will never etc. As a small side benefit, we even managed to close a whole Trello board. Not something that happens often.

The real test will come on Tuesday 22nd, when the usual post-[recess](https://api.parliament.uk/egg-timer/houses/1/recess-dates/) written question deluge is expected to hit our barricades. At which point, we hope we'll no longer be sticking fingers in computational dykes. As it were. Top work our Jianhan, top work crack librarians, top work Lydia.

## Farewell then, Developer Jon

Last time out, we [also reported that Developer Jon had escaped from under his tottering tower of consolidation tickets and started work on search aliases and query expansion](https://ukparliament.github.io/ontologies/meta/weeknotes/2025/12/#new-old-search). A corner having been turned, [new, old search](https://parliamentary-search-265cced0397e.herokuapp.com/) was finally starting to feel like old, old search. In a good way, being no longer entirely reliant on what the user typed but instead first sending their input text to our taxonomy API to be turned into synonyms and tokens. Lovely stuff.

Unfortunately, it was at this point that Jon's contract expired. Altogether less lovely. Despite the very best efforts of Delivery Manager Lydia, it would not appear that the loss of our only frontend developer is easily mitigated. We're told that our stakeholders are happy for the beta launch of new, old search to slip to September. Well, there's nothing quite like optimism.

For understandable reasons, if you've only been reading these notes to follow progress on new, old search, you may wish to tune out for a wee while. We remain hopeful that a developer will be found by some means from somewhere, but that may take some time. Until then, we have a bunch of work to do to tidy both [our Solr backend](https://trello.com/b/XSr1Ylhw/search) and our deployment patterns, so, when a developer finally does arrive, they'll have more fertile ground to work upon. That should at least keep our Jianhan and [Young Robert](https://bsky.app/profile/robert-brook.com) busy.

## Taxonomic liberation (or, toward a single subject view of the Library)

With not much search work to be getting on with - or at least no one to be getting on with it - attentions have turned back to attempts to liberate our taxonomy with the long term goal of providing a Single Subject View of the Library&trade;. In the short term, that means replacing the Library's Subject Specialist Finder, which currently takes the form of a book and a book on a screen cobbled together from bits and bobs of spreadsheets. Its putative replacement associates Library researchers with subjects by means of a specialism, importing Research Briefings indexed with the same subject taxonomy for good measure.

The whole thing got into a bit of a muddle when we discovered we were importing our topic taxonomy alongside our subjects taxonomy. A very different thing which we plan to deprecate in the not too distant. You'll just have to trust us on this. Equally unfortunately, we were also importing topic taxonomy-based indexings for [Research Briefings](https://commonslibrary.parliament.uk/type/research-briefing/) and associating our specialists with topic terms. The first of these problems [has now been fixed](https://trello.com/c/t500QiJm/201-mirage-to-stop-importing-indexings-to-topic-terms-on-research-briefings-from-solr), the second is [on its way to being fixed](https://trello.com/c/hH731rh5/228-strip-out-any-specialisms-related-to-a-topic-term) and [our taxonomy import requirements have been respecified](https://trello.com/c/k2oZPEru/214-configure-mirage-to-only-import-concepts-we-want).

A whole bunch of other bugs have also hit the happy pile, but, given the Single Subject View of the Library&trade; contains a small amount of personal information, it's all locked up behind an authentication layer and we can't point you at it. So we won't bore you with details here. Rest assured, it's all positive progress and possibly something of a goalline clearance.

## If you must grab our stuff, at least try to be polite about it (polemic)

Our regular reader will be aware that we run a small stable of librarian adjacent web applications. Or our 'productivity suite', as Young Robert might say. They'll also be aware that [Shedcode](https://shedcode.co.uk/) [James](https://mastodon.me.uk/@jamesjefferies) has spent much of the last month upgrading them. Or 'hardening them', in Young Robert speak. In the course of that work, James has also rolled out [Rollbar](https://github.com/rollbar/rollbar-gem) for each and every application. If you're unfamiliar with Rollbar, it's provides monitoring of errors in applications without the need to parse [Ruby](https://en.wikipedia.org/wiki/Ruby_(programming_language)) logs. The latter being something we'd not wish on anyone.

Now the primary purpose of rolling out Rollbar is to spot errors we've made. None of us being perfect, such errors do happen. For instance, it turned out that Michael had accidentally removed a partial from our [election results](https://electionresults.parliament.uk/) application that was still very much in use, causing one of our boundary set aggregations to fail. Not good. But Rollbar alerted us and that slight snaffle was [cleared up in a matter of minutes](https://electionresults.parliament.uk/boundary-sets/6/by-elections). All good.

Less good is Rollbar alerting us to errors other people are making. In this case a whole bunch of chaps attempting to train their AI efforts by scraping everything they can scrape off the web and not doing that in a particularly polite fashion. So it turned out our [Procedure Browseable Space](https://api.parliament.uk/procedure-browser)&trade; was getting absolutely hammered by the magic sand lads. And not only hammered for URLs that exist, but - in the case of the Amazon AI bot - also hammered for URLs that do not exist and will never exist. URLs such as:

<code>https://api.parliament.uk/procedure-browser/work-packages/https:%2F%2Fid.parliament.uk%2Fa0aejkro</code>

being called 4,600 times, quickly blowing through the 5,000 error limits on James' Rollbar account. Lads, please. You'd think the old AIs would be well-trained enough to recognise that as a pretty unlikely URL. It would seem not. James has now added a catch-all route defaulting to a 404, which has calmed matters considerably but the point stands. There has been no golden age of history when all crawlers crawled politely, but the whole thing is getting ridiculous.

That this news came through from James on the same day [Jeremy](https://adactio.com/) pressed publish on his [Denial](https://adactio.com/journal/21831) post was a strange coincidence. Potential harms of Large Language Models are often focused on the output end of the spectrum, but the input end comes with its own challenges. When 'hyper-aggressive LLM crawlers' are implementing what amount to D[DOS](https://en.wikipedia.org/wiki/Denial-of-service_attack) attacks on the free and open internet, we have problems. Expanding on the coincidence, that very same day, Young Robert popped into Slack to post a [47,189 line script that attempts to ban such traffic](https://alexschroeder.ch/admin/ban-cidr). That's modern web development for you, he added.

## I am a procedural cartographer - to [the tune of the Palace Brothers](https://www.youtube.com/watch?v=owvF3Vb0JhA&ab_channel=tomkat69pc)

With the whole team still missing Librarian Jayne, map making has temporarily passed to [Librarian Ayesha](https://bsky.app/profile/askalibrarylady.bsky.social) and her computational helpmate [Michael](https://bsky.app/profile/fantasticlife.bsky.social). Kicking off with the simple stuff, this week saw yet another select committee added to the [House of Commons half](https://ukparliament.github.io/ontologies/procedure/maps/legislation/secondary/proposed-negative-sis/commons-committees/commons-committees.pdf) of our [proposed negative statutory instrument map](https://ukparliament.github.io/ontologies/procedure/maps/legislation/secondary/proposed-negative-sis/proposed-negative-sis.pdf), this time in the shape of the [Energy Security and Net Zero Committee](https://committees.parliament.uk/committee/664/energy-security-and-net-zero-committee/). That the [European Statutory Instruments Committee](https://committees.parliament.uk/committee/393/european-statutory-instruments-committee/) was set up under a temporary standing order - and that the adoption of its sifting responsibilities has now passed to the many and varied departmental committees - has caused one hell of a lot of work here. Not that we're ones to complain. But does nobody ever think of the librarians?

## Noun / verb confusion in the [CRAG](https://www.legislation.gov.uk/ukpga/2010/25/part/2)ing area

Entering more choppy waters, we also saw our second ever extension of [treaty period A](https://www.legislation.gov.uk/ukpga/2010/25/part/2#section-20-2) by means of a ministerial statement. We can only assume that someone treaty-related once told us that extension by statement was possible and we automatically jumped to the conclusion that that meant an oral or written statement being made to the House. At least that's what our [scope and link notes](https://api.parliament.uk/procedure-browser/steps/1O5qs3hp) suggest. After all, when one hears the words 'ministerial statement' the first verb that springs to mind is 'making', not 'laying'.

Unfortunately, it appears we did not take the time to do what we usually do and [read the blasted legislation](https://www.legislation.gov.uk/ukpga/2010/25/section/21), which has "[t]he Minister does that by laying before Parliament a statement". The 'laying' of a 'statement'? Whoever heard of such a thing? Papers are laid, statements are made, surely? Maybe the drafter didn't bother to check. Or possibly we're parodying our own pedantry.

That the only time we've seen this happen before, the 'laid statement' was accompanied by [a written statement](https://questions-statements.parliament.uk/written-statements/detail/2023-09-04/hcws999), and that, this time around, time constraints meant no written statement was made, only added to our confusion.

Anyway, legislation finally read, that step has been [actualised](https://ukparliament.github.io/ontologies/procedure/procedure-ontology#d4e508) for [only the second time in its life](https://api.parliament.uk/procedure-browser/steps/1O5qs3hp/business-items), and has now found its way to the [timeline for the One Hundred Year Partnership Agreement between the United Kingdom of Great Britain and Northern Ireland and Ukraine](https://api.parliament.uk/procedure-browser/work-packages/Dhk3Z2oN#business-item-UCab9E70-actualising-1O5qs3hp). Which puts that problem neatly to bed. Fine work Librarian Ayesha.

## Choppier waters still

Ayesha and Michael were back on duty when a request came in from the [Secondary Legislation Scrutiny Committee](https://committees.parliament.uk/committee/255/secondary-legislation-scrutiny-committee/) requesting figures for the number of [statutory instruments they've considered](https://api.parliament.uk/procedure-browser/steps/JcCYkCt7/business-items), broken down by the number they'd [raised concerns about](https://api.parliament.uk/procedure-browser/steps/Kn7FknDd/business-items) and the number they'd [noted as being of interest](https://api.parliament.uk/procedure-browser/steps/Dxba45JM/business-items). And then [the rest](https://api.parliament.uk/procedure-browser/steps/2Etk3rF5/business-items). This further complicated by the request being scoped from April 2004 to April 2005.

Unable to call on Librarian Jayne's [SPARQL](https://en.wikipedia.org/wiki/SPARQL)ing excellence, they at least had our shiny, new Procedure Browsable Space&trade; and its rather nifty 'business items actualising a step' aggregations to rely on. Once they'd got past the realisation that [the SLCS also considers PNSIs](https://api.parliament.uk/procedure-browser/procedures/iCdMN1MW/steps/JcCYkCt7), they managed to grab all the data they needed and [pop it in a spreadsheet](https://docs.google.com/spreadsheets/d/18r8fU9jdjDGjvcST47jNNnBIqnFF6oO-lCv8wSN-WA0/edit?usp=sharing). Only to be faced by numbers that didn't quite add up. Which at least gave Michael the opportunity to tell his one and only computer joke:

"There are only two problems in computer science," he explained, building up to the punchline. "naming things, cache invalidation, and off-by-one errors." How we laughed.

Anyway, data assembled, Ayesha and Michael also realised they lacked the kind of spreadsheet skills that people who *really* know how to wield a spreadsheet possess. Luckily [Librarian Emily](https://bsky.app/profile/emilyjdavi.bsky.social) stepped in and managed to weed her way though everything that appeared on one sheet that also appeared on another, whittling the whole thing down to one stray actualisation. Which has now been fixed. Data improved *and* and an enquiry successfully answered. Quite the adventure.

In the course of that work, Michael also added CSV downloads for [business items actualising a given step](https://api.parliament.uk/procedure-browser/steps/JpQ96n8T/business-items) to our Procedure Browsable Space. Which should make similar enquiries in the future easier still. We hope.

## Psephologising wildly

Our only real bit of interesting news, psephologically speaking, is the addition of [by-election data for Parliament 57](https://electionresults.parliament.uk/parliament-periods/57#by-elections). This thanks to more excellent librarianship from Anna and Emily. It means we're only two Parliament's away - and keeping tabs on whatever happens in this Parliament - from reaching general election / by-election parity. Lovely stuff.

All other efforts have been mainly concerned with aligning labels and identifiers across assorted systems. Which is essential plumbing but pretty boring work, so only recorded here for completeness.

First off, [records](https://electionresults.parliament.uk/political-parties/54) [for](https://electionresults.parliament.uk/political-parties/131) [four](https://electionresults.parliament.uk/political-parties/73) [parties](https://electionresults.parliament.uk/political-parties/57) in our election results database have been updated to match the names registered with the [Electoral Commission](https://www.electoralcommission.org.uk/). Now, if we ruled the school, it's more than possible that we'd introduce legislation to make it mandatory for registered party names to include the word 'party'. Either that or make it mandatory that they do not. The current mixed economy making it very difficult for our poor old computers to render any sentence involving a party name. But that is by-the-by.

Elsewhere, we've been hard at work updating constituency names from the 2005/10 boundary sets to match the legislation across [MNIS](https://data.parliament.uk/membersdataplatform/#), election results and the [maiden speech PFF](https://commonslibrary.parliament.uk/research-briefings/sn04588/). Weston-super-Mare now being [Weston-Super-Mare](https://electionresults.parliament.uk/constituency-areas/624) being just one example. Truly a thing to celebrate.

Back in MNISland, [Librarian Phil](https://bsky.app/profile/philbgorman.bsky.social) has applied [ONS](https://www.ons.gov.uk/)-issued geographic codes to all of the 1997 constituencies in England and Wales. Those for Northern Ireland and Scotland not being available. Off the back of which he's also created a spreadsheet mapping constituency identifiers, names, geographic codes, start dates and end dates. Which Michael is in the process of taking and using to [fix election results constituency names](https://github.com/ukparliament/psephology/blob/main/lib/tasks/25-align-constituencies-to-mnis/align-constituencies-to-mnis.rake#L6) and [add any missing MNIS identifiers](https://github.com/ukparliament/psephology/blob/main/lib/tasks/25-align-constituencies-to-mnis/align-constituencies-to-mnis.rake#L63). All of which leaves with more interoperable datasets and in a position to import the maiden speech PFF once it's undergone similar treatment. We never promised this would be interesting.



